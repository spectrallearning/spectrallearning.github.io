<html>
  <head>
    <title>Workshop on Method of Moments and Spectral Learning (ICML 2014)</title>
    <link rel="stylesheet" href="style.css" />
  </head>
 
  <body>
    <div class="nav">
      <ul>
        <li><a href="index.html">Main</a></li>
        <li><a href="cfp.html">Call for papers</a></li>
        <li><a href="invited.html">Invited speakers</a></li>
        <li><a href="schedule.html">Schedule and abstracts</a></li>
        <li><a href="bib.html">Selected bibliography</a></li>
        <li><a href="past.html">Past workshops and tutorials</a></li>
        <li><a href="organization.html">Organization</a></li>
      </ul>
    </div>

    <div class="main">
      <h1>Workshop on Method of Moments and Spectral Learning (<a href="http://icml.cc/2014/">ICML 2014</a>)</h1>
<h2>Location: Convention Hall No. 4E (Level 1 of the Beijing International Convention Center)</h2>
      
      <p>
      Many problems in machine learning involve collecting high-dimensional
      multivariate observations or sequences of observations, and then fitting
      a compact model which explains these observations.  The predominant
      approaches used in machine learning for fitting models are based either
      on the principle of maximum likelihood or Bayesian inference.  However,
      the algorithms used with these approaches (e.g.,
      Expectation-Maximization) are known to suffer from slow convergence or
      poor quality local optima.
      </p>

      <p>
      In the past several years, the machine learning and computer science
      communities have revisited a classical statistical approach called the
      method of moments, and designed computationally efficient algorithms
      based on this approach to tackle challenging learning problems.  Many of
      these algorithms have been based on spectral decompositions of moment
      matrices or other algebraic structures, and hence have also gone by the
      name of "spectral learning" algorithms.  In contrast to algorithms like
      E-M, these algorithms come with polynomial computational and sample
      complexity guarantees.  Moreover, they have been applied to learn the
      structure and parameters of many models including predictive state
      representations, finite state transducers, hidden Markov models, latent
      trees, latent junction trees, probabilistic context free grammars, and
      mixture/admixture models.  They have also been applied to a wide range of
      application domains including system identification, video modeling,
      speech modeling, robotics, and natural language processing.
      </p>

      <p>
      The focus of this workshop will be on spectral learning algorithms and
      the application of the method of moments to machine learning problems.
      We would like the workshop to be as inclusive as possible and encourage
      paper submissions and participation from a wide range of research related
      to this focus.
      </p>

      <h2>Important dates</h2>

      <ul>
        <li>Submission deadline: April 10, 2014</li>
        <li>Notification of acceptance: April 21, 2014</li>
        <li>Workshop: <b>Wednesday, June 25, 2014</b></li>
      </ul>

    </div>
  </body>

</html>
